{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../tasks')\n",
    "from database_utils import Database\n",
    "\n",
    "from data import ALL_REGRESSION_DATATSETS, ALL_CLASSIFICATION_DATATSETS\n",
    "\n",
    "regression_datasets = list(ALL_REGRESSION_DATATSETS.keys())\n",
    "regression_datasets.sort()\n",
    "\n",
    "classification_datasets = list(ALL_CLASSIFICATION_DATATSETS.keys())\n",
    "classification_datasets.sort()\n",
    "\n",
    "# with Database('../results/results.db') as db:\n",
    "#     db.delete('regression', {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     dataset      N   D             lin            SVGP            DGP  \\\n",
      "0     boston    506  13  -0.644 (0.021)  -0.189 (0.019)                  \n",
      "1   concrete   1030   8  -0.953 (0.016)  -0.353 (0.017)                  \n",
      "2     energy    768   8  -0.220 (0.036)   1.241 (0.013)                  \n",
      "3     kin8nm   8192   8  -1.151 (0.006)  -0.383 (0.005)                  \n",
      "4      naval  11934  12  -0.489 (0.005)   0.726 (0.460)                  \n",
      "5      power   9568   4  -0.098 (0.010)   0.031 (0.011)  0.031 (0.014)   \n",
      "6    protein  45730   9  -1.257 (0.002)  -1.110 (0.002)                  \n",
      "7    winered   1599  11  -1.208 (0.019)  -1.163 (0.021)                  \n",
      "8  winewhite   4898  12  -1.254 (0.012)  -1.167 (0.009)                  \n",
      "9      yacht    308   6  -0.929 (0.026)   1.956 (0.043)  2.273 (0.061)   \n",
      "\n",
      "              svm             knn              rf             gbm  \\\n",
      "0  -0.157 (0.026)  -0.467 (0.042)  -0.940 (0.087)  -0.642 (0.077)   \n",
      "1  -0.558 (0.034)  -0.828 (0.032)  -1.871 (0.185)  -0.440 (0.051)   \n",
      "2   0.038 (0.050)  -0.022 (0.080)  -0.371 (0.498)   1.603 (0.049)   \n",
      "3  -0.273 (0.014)  -0.684 (0.010)  -2.217 (0.053)  -1.023 (0.006)   \n",
      "4   0.034 (0.009)   0.740 (0.035)   0.309 (0.154)  -0.088 (0.010)   \n",
      "5   0.034 (0.012)   0.046 (0.018)  -1.254 (0.089)   0.066 (0.013)   \n",
      "6  -1.150 (0.003)  -1.013 (0.006)  -2.245 (0.014)  -1.156 (0.003)   \n",
      "7  -1.174 (0.030)  -1.280 (0.038)  -2.430 (0.175)  -1.206 (0.032)   \n",
      "8  -1.161 (0.010)  -1.230 (0.013)  -2.449 (0.075)  -1.161 (0.010)   \n",
      "9  -0.614 (0.091)  -1.155 (0.101)  -0.182 (0.583)  -0.590 (0.707)   \n",
      "\n",
      "               ab             mlp  \n",
      "0  -0.368 (0.031)  -0.228 (0.035)  \n",
      "1  -0.678 (0.027)  -0.433 (0.039)  \n",
      "2   0.237 (0.011)   0.121 (0.048)  \n",
      "3  -1.191 (0.007)  -0.259 (0.012)  \n",
      "4  -1.297 (0.006)   1.196 (0.028)  \n",
      "5  -0.309 (0.012)   0.002 (0.011)  \n",
      "6  -1.359 (0.004)  -1.092 (0.005)  \n",
      "7  -1.176 (0.026)  -1.189 (0.031)  \n",
      "8  -1.228 (0.010)  -1.170 (0.011)  \n",
      "9   0.799 (0.111)  -0.090 (0.101)  \n"
     ]
    }
   ],
   "source": [
    "models_names = [['linear', 'lin'],\n",
    "                ['variationally_sparse_gp', 'SVGP'],\n",
    "                ['deep_gp_doubly_stochastic','DGP'],\n",
    "                ['svm', 'svm'],\n",
    "                ['knn', 'knn'],\n",
    "                ['random_forest', 'rf'],\n",
    "                ['gradient_boosting_machine', 'gbm'],\n",
    "                ['adaboost', 'ab'],\n",
    "                ['mlp', 'mlp'],\n",
    "                ]\n",
    "\n",
    "fields = ['dataset', 'N', 'D']\n",
    "fields = fields + [m[1] for m in models_names]\n",
    "results = {f:[] for f in fields}\n",
    "\n",
    "for dataset in regression_datasets:\n",
    "    results['dataset'].append(dataset)\n",
    "    results['N'].append(ALL_REGRESSION_DATATSETS[dataset].N)\n",
    "    results['D'].append(ALL_REGRESSION_DATATSETS[dataset].D)\n",
    "    \n",
    "    with Database('../results/results.db') as db:\n",
    "        for model, name in models_names:\n",
    "            res = db.read('regression', ['test_loglik'], {'model':model, 'dataset':dataset})\n",
    "            \n",
    "            if len(res) > 1:\n",
    "                L = [float(l[0]) for l in res]\n",
    "                m = np.average(L)\n",
    "                if m <100 and m>-100:\n",
    "                    stderr = np.std(L)/float(len(L))**0.5\n",
    "                    r = '{:.3f} ({:.3f})'.format(m, stderr)\n",
    "                else:\n",
    "                    r = 'nan'\n",
    "            else:\n",
    "                r = ''\n",
    "            results[name].append(r)\n",
    "\n",
    "# print(pandas.DataFrame(results).to_latex(columns=fields, index=False))\n",
    "print(pandas.DataFrame(results, columns=fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dataset      N    D   K     lin    SVGP     DGP     svm     knn  \\\n",
      "0       abalone   4177    9   3  -0.754  -2.214  -2.196  -0.730  -2.169   \n",
      "1    acute-infl    120    7   2  -0.069  -0.009  -0.317  -0.019  -0.000   \n",
      "2    acute-neph    120    7   2  -0.032  -0.006  -0.315  -0.020  -0.000   \n",
      "3         adult  48842   15   2  -0.348  -0.323  -0.322  -0.363  -1.109   \n",
      "4     annealing    898   32   5  -0.479  -1.645  -1.420  -0.509  -1.197   \n",
      "5    arrhythmia    452  263  13  -1.369  -1.390  -1.266  -1.213  -7.528   \n",
      "6    audiology-    196   60  18  -1.181  -1.072  -1.197  -1.167  -2.101   \n",
      "7    balance-sc    625    5   3  -0.178  -0.036  -0.053  -0.176  -0.652   \n",
      "8      balloons     16    5   2  -1.341  -1.051  -0.933  -0.885  -0.714   \n",
      "9          bank   4521   17   2  -0.259  -0.248  -0.249  -0.277  -1.287   \n",
      "10        blood    748    5   2  -0.510  -0.509  -0.494  -0.539  -1.854   \n",
      "11   breast-can    286   10   2  -0.182  -0.121  -0.196  -0.176  -0.406   \n",
      "12   breast-can    699   10   2  -0.052  -0.051  -0.067  -0.043  -0.416   \n",
      "13   breast-can    569   31   2  -0.043  -0.037  -0.075  -0.058  -0.100   \n",
      "14   breast-can    198   34   2  -0.925  -0.743  -0.691  -0.760  -1.878   \n",
      "15   breast-tis    106   10   6  -0.754  -0.164  -0.362  -0.675  -0.409   \n",
      "16          car   1728    7   4  -0.457  -0.016  -0.030  -0.064  -0.193   \n",
      "17   cardiotoco   2126   22  10  -0.705  -0.879  -0.740  -0.500  -1.750   \n",
      "18   cardiotoco   2126   22   3  -0.267  -0.407  -0.331  -0.241  -0.545   \n",
      "19   chess-krvk  28056    7  18  -1.369  -0.505  -0.362  -0.088  -0.545   \n",
      "20   chess-krvk   3196   37   2  -0.060  -0.033  -0.077  -0.020  -0.223   \n",
      "21   congressio    435   17   2  -0.615  -0.622  -0.634  -0.631  -2.514   \n",
      "22   conn-bench    208   61   2  -0.087  -0.106  -0.210  -0.039  -0.157   \n",
      "23   conn-bench    990   12  11  -1.127  -0.041  -0.045  -0.111  -0.052   \n",
      "24    connect-4  67557   43   2  -0.536  -0.406          -0.328  -0.927   \n",
      "25      contrac   1473   10   3  -0.871  -1.220  -0.459  -0.691  -2.570   \n",
      "26   credit-app    690   16   2  -0.363  -0.302  -0.312  -0.328  -0.670   \n",
      "27   cylinder-b    512   36   2  -0.585  -0.479  -0.519  -0.485  -0.894   \n",
      "28   dermatolog    366   35   6  -0.183  -0.132  -0.135  -0.186  -0.849   \n",
      "29   echocardio    131   11   2  -0.486  -0.470  -0.460  -0.522  -2.288   \n",
      "..          ...    ...  ...  ..     ...     ...     ...     ...     ...   \n",
      "91      semeion   1593  257  10  -0.469  -0.234          -0.142  -0.518   \n",
      "92      soybean    683   36  18  -0.419  -0.089  -0.127  -0.423  -1.078   \n",
      "93     spambase   4601   58   2  -0.022  -0.018  -0.063  -0.050  -0.256   \n",
      "94        spect    265   23   2  -0.635  -0.675  -0.653  -0.658  -2.663   \n",
      "95       spectf    267   45   2  -0.145  -0.077  -0.206  -0.237  -0.190   \n",
      "96   statlog-au    690   15   2  -0.628  -0.627  -0.631  -0.623  -1.350   \n",
      "97   statlog-ge   1000   25   2  -0.490  -0.505  -0.510  -0.562  -1.844   \n",
      "98   statlog-he    270   14   2  -0.337  -0.321  -0.323  -0.321  -1.200   \n",
      "99   statlog-im   2310   19   7  -0.346  -0.115  -0.058  -0.119  -0.277   \n",
      "100  statlog-la   6435   37   6  -0.490  -0.439  -0.433  -0.260  -0.472   \n",
      "101  statlog-sh  58000   10   7  -0.228  -0.027  -0.008  -0.009  -0.027   \n",
      "102  statlog-ve    846   19   4  -0.437  -0.719  -0.560  -0.373  -1.103   \n",
      "103  steel-plat   1941   28   7  -0.307  -0.060  -0.091  -0.157  -0.663   \n",
      "104  synthetic-    600   61   6  -0.102  -0.014  -0.017  -0.035  -0.020   \n",
      "105    teaching    151    6   3  -0.852  -1.219  -1.192  -0.914  -0.707   \n",
      "106     thyroid   7200   22   3  -0.139  -0.082  -0.068  -0.066  -0.681   \n",
      "107  tic-tac-to    958   10   2  -0.026  -0.005  -0.024  -0.002  -0.000   \n",
      "108     titanic   2201    4   2  -0.431  -0.020  -0.043  -0.137  -0.000   \n",
      "109      trains     10   30   2  -0.159  -0.693  -0.667  -2.040  -0.511   \n",
      "110     twonorm   7400   21   2  -0.059  -0.061  -0.065  -0.060  -0.155   \n",
      "111  vertebral-    310    7   2  -0.033  -0.015  -0.060  -0.012  -0.016   \n",
      "112  vertebral-    310    7   3  -0.096  -0.005  -0.037  -0.043  -0.057   \n",
      "113  wall-follo   5456   25   4  -0.713  -0.373  -0.278  -0.305  -1.134   \n",
      "114    waveform   5000   22   3  -0.315  -0.685  -0.454  -0.328  -0.715   \n",
      "115  waveform-n   5000   41   3  -0.342  -0.875  -0.562  -0.386  -0.940   \n",
      "116        wine    178   14   3  -0.066  -0.043  -0.046  -0.069  -0.000   \n",
      "117  wine-quali   1599   12   6  -0.968  -2.390  -2.153  -0.860  -2.833   \n",
      "118  wine-quali   4898   12   7  -1.075  -3.099  -2.636  -0.991  -3.135   \n",
      "119       yeast   1484    9  10  -1.057  -2.869  -2.534  -0.982  -4.304   \n",
      "120         zoo    101   17   7  -0.207  -0.028  -0.047  -0.230  -0.000   \n",
      "\n",
      "          nb       dt      rf     gbm      ab     mlp  \n",
      "0     -1.882  -10.576  -1.276  -0.654  -1.055  -0.692  \n",
      "1     -1.731   -0.000  -0.036  -0.000  -0.006  -0.033  \n",
      "2     -0.098   -0.000  -0.018  -0.000  -0.000  -0.020  \n",
      "3     -0.827   -5.255  -0.704  -0.295  -0.665  -0.318  \n",
      "4     -6.825   -2.456  -0.169  -0.134  -1.206  -0.402  \n",
      "5    -22.225  -11.413  -3.073  -1.612  -2.312  -1.256  \n",
      "6    -17.960   -2.763  -0.480  -0.849  -2.530  -0.753  \n",
      "7     -0.345   -3.947  -0.714  -0.270  -0.990  -0.083  \n",
      "8     -5.029  -27.631  -1.060  -6.096  -9.501  -1.743  \n",
      "9     -0.561   -3.721  -0.621  -0.230  -0.645  -0.296  \n",
      "10    -0.766   -7.737  -1.525  -0.535  -0.680  -0.485  \n",
      "11    -0.176   -0.000  -0.037  -0.000  -0.000  -0.156  \n",
      "12    -0.060   -0.789  -0.047  -0.033  -0.534  -0.026  \n",
      "13    -0.267   -0.970  -0.107  -0.036  -0.434  -0.031  \n",
      "14    -3.786   -9.671  -1.906  -1.007  -0.660  -0.856  \n",
      "15    -0.262   -5.024  -0.523  -1.647  -1.570  -0.392  \n",
      "16    -0.939   -0.799  -0.291  -0.073  -0.328  -0.063  \n",
      "17    -2.598   -4.670  -0.533  -0.454  -1.774  -0.454  \n",
      "18    -1.827   -1.686  -0.256  -0.146  -0.897  -0.309  \n",
      "19    -0.077   -0.000  -0.072  -0.001  -1.589  -0.029  \n",
      "20    -8.227   -0.000  -0.026  -0.000  -0.005  -0.021  \n",
      "21    -0.872  -11.304  -3.780  -0.684  -0.690  -0.692  \n",
      "22    -1.044   -0.000  -0.175  -0.000  -0.000  -0.167  \n",
      "23    -0.759   -3.628  -0.285  -0.154  -2.142  -0.112  \n",
      "24    -1.267   -5.161  -0.450  -0.389  -0.680  -0.300  \n",
      "25    -1.260   -0.000  -0.177  -0.000  -0.627  -0.494  \n",
      "26    -0.866   -0.801  -0.219  -0.083  -0.592  -0.302  \n",
      "27    -5.546   -4.251  -0.490  -0.441  -0.652  -0.459  \n",
      "28    -3.734   -2.240  -0.185  -0.152  -0.390  -0.138  \n",
      "29    -2.583   -7.895  -2.255  -0.743  -0.591  -0.452  \n",
      "..       ...      ...     ...     ...     ...     ...  \n",
      "91    -4.807   -5.872  -0.570  -0.108  -1.737  -0.180  \n",
      "92    -0.928   -0.000  -0.169  -0.088  -2.354  -0.248  \n",
      "93    -2.946   -0.000  -0.017  -0.000  -0.000  -0.032  \n",
      "94    -1.523  -13.304  -1.621  -0.892  -0.687  -0.908  \n",
      "95    -4.475   -2.047  -0.237  -0.473  -0.078  -0.090  \n",
      "96    -0.655  -10.011  -1.041  -0.624  -0.675  -0.661  \n",
      "97    -1.248   -8.842  -0.854  -0.544  -0.679  -0.729  \n",
      "98    -0.787   -5.117  -0.421  -0.392  -0.666  -0.449  \n",
      "99    -1.587   -0.957  -0.097  -0.033  -0.884  -0.062  \n",
      "100   -3.438   -3.690  -0.474  -0.228  -1.264  -0.222  \n",
      "101   -0.502   -0.000  -0.001  -0.001  -0.780  -0.004  \n",
      "102   -2.605   -7.477  -0.734  -0.349  -1.127  -0.302  \n",
      "103   -1.203   -0.142  -0.284  -0.031  -1.003  -0.068  \n",
      "104   -0.000   -0.461  -0.097  -0.031  -1.339  -0.016  \n",
      "105   -0.690   -3.454  -2.117  -0.667  -0.819  -0.922  \n",
      "106  -14.645   -0.038  -0.028  -0.005  -0.401  -0.026  \n",
      "107   -0.055   -0.000  -0.016  -0.000  -0.000  -0.006  \n",
      "108   -0.704   -0.125  -0.006  -0.022  -0.634  -0.110  \n",
      "109  -27.631   -0.000  -0.223  -0.000  -0.000  -0.082  \n",
      "110   -0.059   -3.883  -0.211  -0.127  -0.609  -0.111  \n",
      "111   -0.001   -0.000  -0.014  -0.000  -0.000  -0.013  \n",
      "112   -0.000   -0.000  -0.028  -0.000  -0.000  -0.039  \n",
      "113   -3.023   -0.304  -0.034  -0.008  -0.725  -0.280  \n",
      "114   -0.679   -7.847  -0.505  -0.328  -0.844  -0.381  \n",
      "115   -0.858   -7.571  -0.455  -0.366  -0.845  -0.833  \n",
      "116   -0.080   -0.000  -0.100  -0.044  -0.000  -0.061  \n",
      "117   -1.524  -10.189  -1.443  -0.905  -1.580  -0.969  \n",
      "118   -1.442  -10.263  -1.981  -0.959  -6.321  -0.980  \n",
      "119   -8.952  -12.239  -2.194  -1.000  -2.245  -0.999  \n",
      "120   -0.000   -0.000  -0.030  -0.000  -0.152  -0.016  \n",
      "\n",
      "[121 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "fields = ['dataset', 'N', 'D', 'K']\n",
    "\n",
    "models_names = [['linear', 'lin'],\n",
    "                ['variationally_sparse_gp', 'SVGP'],\n",
    "                ['deep_gp_doubly_stochastic','DGP'],\n",
    "                ['svm', 'svm'],\n",
    "                ['knn', 'knn'],\n",
    "                ['naive_bayes', 'nb'],\n",
    "                ['decision_tree', 'dt'],\n",
    "                ['random_forest', 'rf'],\n",
    "                ['gradient_boosting_machine', 'gbm'],\n",
    "                ['adaboost', 'ab'],\n",
    "                ['mlp', 'mlp'],\n",
    "                ]\n",
    "                \n",
    "fields = fields + [m[1] for m in models_names]\n",
    "results = {f:[] for f in fields}\n",
    "\n",
    "with Database('../results/results.db') as db:\n",
    "\n",
    "    for dataset in classification_datasets:\n",
    "        results['dataset'].append(dataset[:10])\n",
    "        results['N'].append(ALL_CLASSIFICATION_DATATSETS[dataset].N)\n",
    "        results['D'].append(ALL_CLASSIFICATION_DATATSETS[dataset].D)\n",
    "        results['K'].append(ALL_CLASSIFICATION_DATATSETS[dataset].K)\n",
    "\n",
    "        for model, name in models_names:\n",
    "            res = db.read('classification', ['test_loglik'], {'model':model, 'dataset':dataset})\n",
    "            if len(res)>0:\n",
    "                L = [float(l[0]) for l in res]\n",
    "\n",
    "                m = np.average(L)\n",
    "                r = '{:.3f}'.format(m)  # only one split run\n",
    "    #             stderr = np.std(L)/float(len(L))**0.5\n",
    "    #             r = '{:.3f} ({:.3f})'.format(m, stderr)\n",
    "            else:\n",
    "                r = ''\n",
    "            results[name].append(r)\n",
    "\n",
    "print(pandas.DataFrame(results, columns=fields))#.to_latex(index=False))\n",
    "\n",
    "#NB the DGP results here are with a too small learning rate but it will do for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fields = ['dataset', 'N', 'D', 'K']\n",
    "\n",
    "# models_names = [['linear', 'lin'],\n",
    "#                 ['variationally_sparse_gp', 'SVGP'],\n",
    "#                 ['deep_gp_doubly_stochastic','DGP'],\n",
    "#                 ['svm', 'svm'],\n",
    "#                 ['knn', 'knn'],\n",
    "#                 ['naive_bayes', 'nb'],\n",
    "#                 ['decision_tree', 'dt'],\n",
    "#                 ['random_forest', 'rf'],\n",
    "#                 ['gradient_boosting_machine', 'gbm'],\n",
    "#                 ['adaboost', 'ab'],\n",
    "#                 ['mlp', 'mlp'],\n",
    "#                 ]\n",
    "                \n",
    "# colours = ['C{}'.format(i) for i in range(10)]\n",
    "\n",
    "# fields = fields + [m[1] for m in models_names]\n",
    "# results = {f:[] for f in fields}\n",
    "\n",
    "\n",
    "# for dataset in classification_datasets[:10]:  # don't show them all...\n",
    "    \n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "#     results['dataset'].append(dataset)\n",
    "#     results['N'].append(ALL_CLASSIFICATION_DATATSETS[dataset].N)\n",
    "#     results['D'].append(ALL_CLASSIFICATION_DATATSETS[dataset].D)\n",
    "#     results['K'].append(ALL_CLASSIFICATION_DATATSETS[dataset].K)\n",
    "\n",
    "#     for (name, model), c in zip(models_names, colours):\n",
    "#         with Database('../results/results.db') as db:\n",
    "#             d = {'iterations':50, 'model':model, 'dataset':dataset}\n",
    "\n",
    "#             res = db.read('active_learning', ['test_loglik', 'total_acc'], d) \n",
    "#         if len(res)>0:\n",
    "#             test_ll = res[0][0]\n",
    "#             test_acc = res[0][1]\n",
    "\n",
    "#             axs[0].plot(test_ll, label=model, color=c)\n",
    "#             axs[1].plot(test_acc, label=model, color=c)\n",
    "\n",
    "#     plt.title('{} {} {} {}'.format(dataset,\n",
    "#                                    ALL_CLASSIFICATION_DATATSETS[dataset].N,\n",
    "#                                    ALL_CLASSIFICATION_DATATSETS[dataset].D,\n",
    "#                                    ALL_CLASSIFICATION_DATATSETS[dataset].K))\n",
    "#     plt.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
